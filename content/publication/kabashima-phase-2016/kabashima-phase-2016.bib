@article{kabashima_phase_2016,
 abstract = {We analyze the matrix factorization problem. Given a noisy measurement of a product of two matrices, the problem is to estimate back the original matrices. It arises in many applications, such as dictionary learning, blind matrix calibration, sparse principal component analysis, blind source separation, low rank matrix completion, robust principal component analysis, or factor analysis. It is also important in machine learning: unsupervised representation learning can often be studied through matrix factorization. We use the tools of statistical mechanics-the cavity and replica methods-to analyze the achievability and computational tractability of the inference problems in the setting of Bayes-optimal inference, which amounts to assuming that the two matrices have random-independent elements generated from some known distribution, and this information is available to the inference algorithm. In this setting, we compute the minimal mean-squared-error achievable, in principle, in any computational time, and the error that can be achieved by an efficient approximate message passing algorithm. The computation is based on the asymptotic state-evolution analysis of the algorithm. The performance that our analysis predicts, both in terms of the achieved mean-squared-error and in terms of sample complexity, is extremely promising and motivating for a further development of the algorithm.},
 author = {Kabashima, Y. and Krzakala, F. and Mézard, M. and Sakata, A. and Zdeborová, L.},
 doi = {10.1109/TIT.2016.2556702},
 file = {IEEE Xplore Abstract Record:/Users/florentkrzakala/Zotero/storage/83XH5XQN/7457269.html:text/html;IEEE Xplore Full Text PDF:/Users/florentkrzakala/Zotero/storage/TGCL2YTD/Kabashima et al. - 2016 - Phase Transitions and Sample Complexity in Bayes-O.pdf:application/pdf},
 issn = {0018-9448},
 journal = {IEEE Transactions on Information Theory},
 keywords = {Algorithm design and analysis, approximate message passing algorithm, asymptotic state-evolution analysis, Bayes methods, Bayes-optimal inference, Bayes-optimal matrix factorization, blind matrix calibration, blind source separation, cavity-replica methods, Complexity theory, computational barriers, computational complexity, dictionary learning, factor analysis, inference mechanisms, inference problems, low rank matrix completion, machine learning, matrix decomposition, mean square error methods, message passing algorithms, minimal mean-squared-error achievable computation, Noise measurement, noisy measurement, phase transitions, Prediction algorithms, Principal component analysis, probabilistic matrix factorization, Probability distribution, random-independent elements, robust principal component analysis, sample complexity, sparse coding, Sparse matrices, sparse principal component analysis, statistical analysis, statistical and computational tradeoff, Statistical inference, statistical mechanics, statistical physics, unsupervised representation learning},
 month = {July},
 number = {7},
 pages = {4228--4265},
 title = {Phase Transitions and Sample Complexity in Bayes-Optimal Matrix Factorization},
 volume = {62},
 year = {2016}
}

