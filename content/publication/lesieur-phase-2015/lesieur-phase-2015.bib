@inproceedings{lesieur_phase_2015,
 abstract = {We study optimal estimation for sparse principal component analysis when the number of non-zero elements is small but on the same order as the dimension of the data. We employ approximate message passing (AMP) algorithm and its state evolution to analyze what is the information theoretically minimal mean-squared error and the one achieved by AMP in the limit of large sizes. For a special case of rank one and large enough density of non-zeros Deshpande and Montanari [1] proved that AMP is asymptotically optimal. We show that both for low density and for large rank the problem undergoes a series of phase transitions suggesting existence of a region of parameters where estimation is information theoretically possible, but AMP (and presumably every other polynomial algorithm) fails. The analysis of the large rank limit is particularly instructive.},
 author = {Lesieur, T. and Krzakala, F. and Zdeborov√°, L.},
 booktitle = {2015 IEEE International Symposium on Information Theory (ISIT)},
 doi = {10.1109/ISIT.2015.7282733},
 file = {IEEE Xplore Abstract Record:/Users/florentkrzakala/Zotero/storage/ULSPB7M6/7282733.html:text/html;Submitted Version:/Users/florentkrzakala/Zotero/storage/QT45YCEL/Lesieur et al. - 2015 - Phase transitions in sparse PCA.pdf:application/pdf},
 keywords = {approximate message passing, Approximation algorithms, Estimation, information theoretically minimal mean-squared error, information theory, Mathematical model, mean square error methods, message passing, Message passing, Noise, non-zero elements, PCA, phase transitions, principal component analysis, Principal component analysis, Sparse matrices},
 month = {June},
 pages = {1635--1639},
 title = {Phase transitions in sparse PCA},
 year = {2015}
}

