---
title: "The mutual information in random linear estimation"
date: 2016-09-01
publishDate: 2019-07-01T14:53:41.561256Z
authors: ["J. Barbier", "M. Dia", "N. Macris", "F. Krzakala"]
publication_types: ["1"]
abstract: "We consider the estimation of a signal from the knowledge of its noisy linear random Gaussian projections, a problem relevant in compressed sensing, sparse superposition codes or code division multiple access just to cite few. There has been a number of works considering the mutual information for this problem using the heuristic replica method from statistical physics. Here we put these considerations on a firm rigorous basis. First, we show, using a Guerra-type interpolation, that the replica formula yields an upper bound to the exact mutual information. Secondly, for many relevant practical cases, we present a converse lower bound via a method that uses spatial coupling, state evolution analysis and the I-MMSE theorem. This yields, in particular, a single letter formula for the mutual information and the minimal-mean-square error for random Gaussian linear estimation of all discrete bounded signals."
featured: false
publication: "*2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)*"
tags: ["code division multiple access", "compressed sensing", "Context", "discrete bounded signals", "Estimation", "Guerra-type interpolation", "heuristic replica method", "I-MMSE theorem", "Integrated circuits", "least mean squares methods", "minimal-mean-square error", "Multiaccess communication", "Mutual information", "noisy linear random Gaussian projections", "Physics", "random Gaussian linear estimation", "random linear estimation", "sparse superposition codes", "spatial coupling", "state evolution analysis", "statistical physics", "Upper bound"]
doi: "10.1109/ALLERTON.2016.7852290"
---

