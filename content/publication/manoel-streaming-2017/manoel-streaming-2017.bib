@inproceedings{manoel_streaming_2017,
 abstract = {In statistical learning for real-world large-scale data problems, one must often resort to “streaming” algorithms which operate sequentially on small batches of data. In this work, we present an analysis of the information-theoretic limits of mini-batch inference in the context of generalized linear models and low-rank matrix factorization. In a controlled Bayes-optimal setting, we characterize the optimal performance and phase transitions as a function of mini-batch size. We base part of our results on a detailed analysis of a mini-batch version of the approximate message-passing algorithm (Mini-AMP), which we introduce. Additionally, we show that this theoretical optimality carries over into real-data problems by illustrating that Mini-AMP is competitive with standard streaming algorithms for clustering.},
 author = {Manoel, A. and Krzakala, F. and Tramel, E. W. and Zdeborová, L.},
 booktitle = {2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
 doi = {10.1109/ALLERTON.2017.8262853},
 file = {IEEE Xplore Abstract Record:/Users/florentkrzakala/Zotero/storage/VNC6IV3C/8262853.html:text/html;Submitted Version:/Users/florentkrzakala/Zotero/storage/BXUUPQIR/Manoel et al. - 2017 - Streaming Bayesian inference Theoretical limits a.pdf:application/pdf},
 keywords = {Algorithm design and analysis, Analytical models, approximate message-passing algorithm, Approximation algorithms, approximation theory, Bayes methods, Bayesian inference streaming, Computational modeling, controlled Bayes-optimal setting, generalized linear models, Inference algorithms, inference mechanisms, information-theoretic limits, large-scale data problems, learning (artificial intelligence), low-rank matrix factorization, matrix algebra, matrix decomposition, message passing, Mini-AMP, mini-batch approximate message passing, mini-batch inference, mini-batch size, mini-batch version, Mutual information, optimal performance, optimisation, phase transitions, Sparse matrices, standard streaming algorithms, statistical learning, theoretical limits, theoretical optimality},
 month = {October},
 pages = {1048--1055},
 shorttitle = {Streaming Bayesian inference},
 title = {Streaming Bayesian inference: Theoretical limits and mini-batch approximate message-passing},
 year = {2017}
}

